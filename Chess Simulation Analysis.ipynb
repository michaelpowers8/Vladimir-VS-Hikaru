{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hikaru Investigation Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error,median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hikaru Big Simulation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(mse):\n",
    "    return mse**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(target, predictions):\n",
    "    mse = round(mean_squared_error(target, predictions),3)\n",
    "    mean_ae = round(mean_absolute_error(target,predictions),3)\n",
    "    rmse = round(mean_squared_error(target, predictions)**0.5,3)\n",
    "    median_ae = round(median_absolute_error(target,predictions),3)\n",
    "    r2 = r2_score(target,predictions)\n",
    "    return [mse,rmse,mean_ae,median_ae,r2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df,x='Number of 40 Win Streaks',y='Hikaru ELO',bins=10)\n",
    "plt.savefig('Number of Streaks By ELO Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Hikaru ELO','Number of 40 Win Streaks']].plot(\n",
    "        x='Hikaru ELO',\n",
    "        y='Number of 40 Win Streaks',\n",
    "        kind='scatter',\n",
    "        title='Number of Streaks VS. Hikaru ELO')\n",
    "plt.savefig('Number of Streaks VS Hikaru ELO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Anonymous GM ELO','Number of 40 Win Streaks']].plot(\n",
    "        x='Anonymous GM ELO',\n",
    "        y='Number of 40 Win Streaks',\n",
    "        kind='scatter',\n",
    "        title='Number of Streaks VS. GM ELO')\n",
    "plt.savefig('Number of Streaks VS GM ELO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Hikaru Score','Number of 40 Win Streaks']].plot(\n",
    "        x='Hikaru Score',\n",
    "        y='Number of 40 Win Streaks',\n",
    "        kind='scatter',\n",
    "        title='Number of Streaks VS. Hikaru Score')\n",
    "plt.savefig('Number of Streaks VS Hikaru Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Anonymous GM Score','Number of 40 Win Streaks']].plot(\n",
    "        x='Anonymous GM Score',\n",
    "        y='Number of 40 Win Streaks',\n",
    "        kind='scatter',\n",
    "        xticks=[i for i in range(0,12000,1000)],\n",
    "        title='Number of Streaks VS. GM Score')\n",
    "plt.savefig('Number of Streaks VS GM ELO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Hikaru ELO')[['Hikaru ELO','Hikaru Biggest Win Streak']].mean().plot(\n",
    "        x='Hikaru ELO',\n",
    "        y='Hikaru Biggest Win Streak',\n",
    "        kind='scatter',\n",
    "        title=\"Hikaru's Average Win Streak by ELO\")\n",
    "plt.savefig('Hikaru Average Win Streak by ELO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Hikaru ELO')[['Hikaru ELO','Hikaru Biggest Win Streak']].median().plot(\n",
    "        x='Hikaru ELO',\n",
    "        y='Hikaru Biggest Win Streak',\n",
    "        kind='scatter',\n",
    "        title=\"Hikaru's Median Win Streak by ELO\")\n",
    "plt.savefig('Hikaru Median Win Streak by ELO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Hikaru ELO')[['Hikaru ELO','Hikaru Biggest Win Streak']].min().plot(\n",
    "        x='Hikaru ELO',\n",
    "        y='Hikaru Biggest Win Streak',\n",
    "        kind='scatter',\n",
    "        title=\"Hikaru's Smallest Win Streak by ELO\")\n",
    "plt.savefig('Hikaru Smallest Win Streak by ELO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Hikaru ELO')[['Hikaru ELO','Hikaru Biggest Win Streak']].max().plot(\n",
    "        x='Hikaru ELO',\n",
    "        y='Hikaru Biggest Win Streak',\n",
    "        kind='scatter',\n",
    "        title=\"Hikaru's Biggest Streak by ELO\")\n",
    "plt.savefig('Hikaru Biggest Streak by ELO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ELO Difference'] = df['Hikaru ELO']-df['Anonymous GM ELO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('ELO Difference')[['ELO Difference','Number of 40 Win Streaks']].mean().plot(\n",
    "        x='ELO Difference',\n",
    "        y='Number of 40 Win Streaks',\n",
    "        kind='scatter',\n",
    "        xticks=[i for i in range(0,800,100)],\n",
    "        title='Number of Streaks By ELO Difference')\n",
    "plt.savefig('Number of Streaks By ELO Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('ELO Difference')[['ELO Difference','Hikaru Biggest Win Streak']].mean().plot(\n",
    "        x='ELO Difference',\n",
    "        y='Hikaru Biggest Win Streak',\n",
    "        kind='scatter',\n",
    "        xticks=[i for i in range(0,800,100)],\n",
    "        title='Longest Win Streak By ELO Difference')\n",
    "plt.savefig('Longest Win Streak By ELO Difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graphs provided, it is very evident that as Hikaru's ELO increased, the number of 40 game win streaks increases linearly. Also, as Hikaru's score increases, the expected number of 40 game win streaks increases exponentially. The larger the difference, the exponentially higher number of 40 game win streaks occurs and an exponential growth in the size of the largest winning streak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('Number of 40 Win Streaks',axis=1)\n",
    "target = df['Number of 40 Win Streaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features,target,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_scaled = features_train.copy()\n",
    "features_test_scaled = features_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(features_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_scaled = scaler.transform(features_train_scaled)\n",
    "features_test_scaled = scaler.transform(features_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = DummyRegressor(strategy=\"mean\")\n",
    "dr.fit(features_train_scaled,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_predictions = dr.predict(features_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(get_scores(target_test,dr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=random_state).fit(features_train_scaled,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr.predict(features_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(get_scores(target_test,lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_parameters = {'random_state':[random_state],\n",
    "                  'warm_start':[True,False],\n",
    "                  'n_estimators':[i for i in range(50,201,50)],\n",
    "                  'max_depth':[None,4,6,8],\n",
    "                  'max_features':[None],\n",
    "                  'min_samples_leaf':[1,3,5],\n",
    "                  'verbose':[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = GridSearchCV(RandomForestRegressor(),\n",
    "                   rfr_parameters,cv=5,\n",
    "                   verbose=10,\n",
    "                   scoring=make_scorer(rmse)).fit(features_train_scaled,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_predictions = rfr.best_estimator_.predict(features_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(get_scores(target_test,rfr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbr_parameters = {'verbose':[0],\n",
    "                  'iterations':[i for i in range(100,1001,200)],\n",
    "                  'early_stopping_rounds':[1,5,10],\n",
    "                  'random_state':[random_state],\n",
    "                  'learning_rate':[0.0005,0.001,0.01],\n",
    "                  'eval_metric':['AUC']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbr = GridSearchCV(CatBoostRegressor(),\n",
    "                   cbr_parameters,\n",
    "                   scoring=make_scorer(rmse),\n",
    "                   cv=5,\n",
    "                   verbose=10).fit(features_train_scaled,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbr_predictions = cbr.best_estimator_.predict(features_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(get_scores(target_test,cbr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_parameters = {'verbose':[0],\n",
    "                  'n_estimators':[i for i in range(50,251,50)],\n",
    "                  'num_leaves':[20,31,45],\n",
    "                  'max_depth':[-1,2,4,6],\n",
    "                  'random_state':[random_state],\n",
    "                  'learning_rate':[0.0005,0.001,0.01,0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = GridSearchCV(LGBMRegressor(),\n",
    "                    lgbm_parameters,\n",
    "                    scoring=make_scorer(rmse),\n",
    "                    cv=5,\n",
    "                    verbose=10).fit(features_train_scaled,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_predictions = lgbm.best_estimator_.predict(features_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(get_scores(target_test,lgbm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_parameters = {'random_state':[random_state],\n",
    "                  'criterion':['squared_error','absolute_error'],\n",
    "                  'max_depth':[None,2,4,6],\n",
    "                  'min_samples_leaf':[1,3,5],\n",
    "                  'min_samples_split':[2,3,4,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = GridSearchCV(DecisionTreeRegressor(),\n",
    "                    dtr_parameters,\n",
    "                    scoring=make_scorer(rmse),\n",
    "                    cv=5,\n",
    "                    verbose=10).fit(features_train_scaled,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_predictions = dtr.best_estimator_.predict(features_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(get_scores(target_test,dtr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=scores,columns=['Mean Squared Error','Reduced Mean Squared Error','Mean Absolute Error','Median Absolute Error','R2'],\n",
    "             index=['Dummy','Logistic','Random Forest','Cat Boost','Light Gradient Boost','Decision Tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_scores = pd.DataFrame(data=scores,\n",
    "                         columns=['Mean Squared Error',\n",
    "                                  'Reduced Mean Squared Error',\n",
    "                                  'Mean Absolute Error',\n",
    "                                  'Median Absolute Error','R2'],\n",
    "                         index=['Dummy','Logistic','Random Forest',\n",
    "                                'Cat Boost','Light Gradient Boost','Decision Tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=  {\n",
    "                    'Dummy':[1/(len(features.columns)-1)]*(len(features.columns)-1),\n",
    "                    'Logistic':[1/(len(features.columns)-1)]*(len(features.columns)-1),\n",
    "                    'Random Forest':rfr.best_estimator_.feature_importances_,\n",
    "                    'Cat Boost':cbr.best_estimator_.get_feature_importance(),\n",
    "                    'Light Gradient':lgbm.best_estimator_.feature_importance(),\n",
    "                    'Decision Tree':dtr.best_estimator_.feature_importances_,\n",
    "                    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
